# NLP_Coursework_Projects-

This repository contains a collection of NLP (Natural Language Processing) lab assignments that I've worked on as part of my coursework. The assignments cover various topics such as text preprocessing, regular expressions, vectorization techniques, and word embeddings.

## Table of Contents

1. [Lab 3 - Regular Expressions in NLP](#lab-3-regular-expressions-in-nlp)
2. [Lab 4 - Text Cleaning with Regular Expressions](#lab-4-text-cleaning-with-regular-expressions)
3. [Lab 6 - Text Vectorization (One-Hot Encoding & Bag of Words)](#lab-6-text-vectorization-one-hot-encoding-bag-of-words)
4. [Lab 8 - Word Embeddings with PPMI & SVD](#lab-8-word-embeddings-with-ppmi-svd)

## Labs

### Lab 3 - Regular Expressions in NLP

In this lab, I explored the fundamentals of **regular expressions (regex)** and how they are used in NLP tasks. The key concepts include meta-characters, quantifiers, and match objects, along with practical applications for text processing and tokenization using **NLTK**.

### Lab 4 - Text Cleaning with Regular Expressions

In this lab, I applied regular expressions to **clean and preprocess** textual data. The tasks involved extracting dates, phone numbers, and emails, as well as general pattern matching techniques.

### Lab 6 - Text Vectorization (One-Hot Encoding & Bag of Words)

This lab focused on **vectorizing** textual data using two common techniques: **One-Hot Encoding** and **Bag of Words (BoW)**. I also implemented **Cosine Similarity** to rank documents based on similarity to a user-provided search query.

## Usage

To explore these labs, open the Jupyter notebooks (`*.ipynb`) in your browser. Each notebook contains detailed code with explanations for performing specific NLP tasks. You can run them interactively on Google Colab or your local machine.

## Requirements

Before running the code, ensure that you have the following libraries installed:

- `nltk`
- `numpy`
- `scikit-learn`
- `pandas`
- `matplotlib`
- `seaborn`
- `gensim`
- `tweepy` (for Twitter data extraction)

You can install the required libraries using `pip`:

## License

This repository is licensed under the MIT License. See the LICENSE file for more details.

## Acknowledgments

- Thanks to [NLTK](https://www.nltk.org/) and [scikit-learn](https://scikit-learn.org/) for their awesome libraries.
- Special thanks to [Tweepy](https://www.tweepy.org/) for helping extract Twitter data.


